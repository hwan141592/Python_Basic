{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this page...\n",
    " - Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow2 API >> Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Model을 구성해주세요.\n",
    "\"\"\"\n",
    "Spec:\n",
    "1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "3. Flatten 레이어\n",
    "4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "\"\"\"\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.Conv2D(64, 3, activation='relu'),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# 여기에 모델을 구성해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 67s 36ms/step - loss: 0.1090 - accuracy: 0.9665\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 65s 35ms/step - loss: 0.0341 - accuracy: 0.9892\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 64s 34ms/step - loss: 0.0204 - accuracy: 0.9932\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 62s 33ms/step - loss: 0.0132 - accuracy: 0.9957\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 62s 33ms/step - loss: 0.0097 - accuracy: 0.9965\n",
      "313/313 - 2s - loss: 0.0505 - accuracy: 0.9874\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05052664130926132, 0.9873999953269958]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow2 API >> Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Spec:\n",
    "0. (28X28X1) 차원으로 정의된 Input\n",
    "1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "3. Flatten 레이어\n",
    "4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "\"\"\"\n",
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(inputs)\n",
    "x = keras.layers.Conv2D(64, 3, activation='relu')(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(128, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "\n",
    "# 여기에 모델을 구성해 주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 64s 34ms/step - loss: 0.1073 - accuracy: 0.9672\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 65s 35ms/step - loss: 0.0347 - accuracy: 0.9890\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 64s 34ms/step - loss: 0.0207 - accuracy: 0.9930\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 65s 35ms/step - loss: 0.0129 - accuracy: 0.9959\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 66s 35ms/step - loss: 0.0090 - accuracy: 0.9972\n",
      "313/313 - 2s - loss: 0.0457 - accuracy: 0.9878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04572214558720589, 0.9878000020980835]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow2 API >> Subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "mnist = keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "x_train=x_train[...,np.newaxis]\n",
    "x_test=x_test[...,np.newaxis]\n",
    "\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclassing을 활용한 Model을 구성해주세요.\n",
    "\"\"\"\n",
    "Spec:\n",
    "0. keras.Model 을 상속받았으며, __init__()와 call() 메소드를 가진 모델 클래스\n",
    "1. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. 64개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "3. Flatten 레이어\n",
    "4. 128개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "5. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "6. call의 입력값이 모델의 Input, call의 리턴값이 모델의 Output\n",
    "\"\"\"\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.conv2 = keras.layers.Conv2D(64, 3, activation='relu')\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(128, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(10, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 65s 35ms/step - loss: 0.1072 - accuracy: 0.9670\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 63s 34ms/step - loss: 0.0346 - accuracy: 0.9891\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 58s 31ms/step - loss: 0.0213 - accuracy: 0.9932\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 61s 33ms/step - loss: 0.0133 - accuracy: 0.9959\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 61s 33ms/step - loss: 0.0094 - accuracy: 0.9967\n",
      "313/313 - 2s - loss: 0.0521 - accuracy: 0.9859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.052141692489385605, 0.9858999848365784]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow2 API >>> CIFAR-100 Dataset\n",
    "### (1) Sequential API 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential Model을 구성해주세요.\n",
    "\"\"\"\n",
    "Spec:\n",
    "1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. pool_size가 2인 MaxPool 레이어\n",
    "3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "4. pool_size가 2인 MaxPool 레이어\n",
    "5. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "6. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "\"\"\"\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(16, 3, activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Conv2D(32, 3, activation='relu'),\n",
    "    keras.layers.MaxPool2D((2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(256, activation='relu'),\n",
    "    keras.layers.Dense(100, activation='softmax')\n",
    "])\n",
    "\n",
    "# 여기에 모델을 구성해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 3.6121 - accuracy: 0.1579\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 2.9213 - accuracy: 0.2814\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 2.6190 - accuracy: 0.3423\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 2.4101 - accuracy: 0.3837\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.2386 - accuracy: 0.4229\n",
      "313/313 - 1s - loss: 2.5746 - accuracy: 0.3608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5745997428894043, 0.36079999804496765]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "# 학습 관련 부분을 작성해주세요\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow2 API >>> CIFAR-100 Dataset\n",
    "### (2) Sequential API 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functional API를 활용한 Model을 구성해주세요.\n",
    "\"\"\"\n",
    "Spec:\n",
    "0. (32X32X3) 차원으로 정의된 Input\n",
    "1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. pool_size가 2인 MaxPool 레이어\n",
    "3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "4. pool_size가 2인 MaxPool 레이어\n",
    "5. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "6. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "\"\"\"\n",
    "\n",
    "inputs = keras.Input(shape=(32, 32, 3))\n",
    "\n",
    "x = keras.layers.Conv2D(16, 3, activation='relu')(inputs)\n",
    "x = keras.layers.MaxPool2D((2,2))(x)\n",
    "x = keras.layers.Conv2D(32, 3, activation='relu')(x)\n",
    "x = keras.layers.MaxPool2D((2,2))(x)\n",
    "x = keras.layers.Flatten()(x)\n",
    "x = keras.layers.Dense(256, activation='relu')(x)\n",
    "predictions = keras.layers.Dense(100, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 3.6249 - accuracy: 0.1545\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.9093 - accuracy: 0.2832\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.6042 - accuracy: 0.3445\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.3961 - accuracy: 0.3913\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 18s 11ms/step - loss: 2.2326 - accuracy: 0.4220\n",
      "313/313 - 1s - loss: 2.6101 - accuracy: 0.3628\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.6101410388946533, 0.3628000020980835]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow2 API >>> CIFAR-100 Dataset\n",
    "### (3) Subclassing 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "# 데이터 구성부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subclassing을 활용한 Model을 구성해주세요.\n",
    "\"\"\"\n",
    "Spec:\n",
    "0. keras.Model 을 상속받았으며, __init__()와 call() 메소드를 가진 모델 클래스\n",
    "1. 16개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "2. pool_size가 2인 MaxPool 레이어\n",
    "3. 32개의 채널을 가지고, 커널의 크기가 3, activation function이 relu인 Conv2D 레이어\n",
    "4. pool_size가 2인 MaxPool 레이어\n",
    "5. 256개의 아웃풋 노드를 가지고, activation function이 relu인 Fully-Connected Layer(Dense)\n",
    "6. 데이터셋의 클래스 개수에 맞는 아웃풋 노드를 가지고, activation function이 softmax인 Fully-Connected Layer(Dense)\n",
    "7. call의 입력값이 모델의 Input, call의 리턴값이 모델의 Output\n",
    "\"\"\"\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.maxpool1 = keras.layers.MaxPool2D((2,2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.maxpool2 = keras.layers.MaxPool2D((2,2))\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 17s 11ms/step - loss: 3.6026 - accuracy: 0.1597\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 19s 12ms/step - loss: 2.8929 - accuracy: 0.2868\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 2.5916 - accuracy: 0.3471\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 2.3788 - accuracy: 0.3917\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 20s 13ms/step - loss: 2.2070 - accuracy: 0.4279\n",
      "313/313 - 1s - loss: 2.5521 - accuracy: 0.3640\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.5521106719970703, 0.36399999260902405]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 학습 설정\n",
    "# 학습 관련 부분을 작성해주세요\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "\n",
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientTape의 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000 10000\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# 데이터 구성부분\n",
    "cifar100 = keras.datasets.cifar100\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "print(len(x_train), len(x_test))\n",
    "\n",
    "# 모델 구성부분\n",
    "class CustomModel(keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = keras.layers.Conv2D(16, 3, activation='relu')\n",
    "        self.maxpool1 = keras.layers.MaxPool2D((2,2))\n",
    "        self.conv2 = keras.layers.Conv2D(32, 3, activation='relu')\n",
    "        self.maxpool2 = keras.layers.MaxPool2D((2,2))\n",
    "        self.flatten = keras.layers.Flatten()\n",
    "        self.fc1 = keras.layers.Dense(256, activation='relu')\n",
    "        self.fc2 = keras.layers.Dense(100, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.maxpool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "model = CustomModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# tf.GradientTape()를 활용한 train_step\n",
    "def train_step(features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(features)\n",
    "        loss = loss_func(labels, predictions)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer custom_model_2 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because its dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "Epoch 0: last batch loss = 4.5026\n",
      "Epoch 1: last batch loss = 4.4731\n",
      "Epoch 2: last batch loss = 4.7483\n",
      "Epoch 3: last batch loss = 4.7745\n",
      "Epoch 4: last batch loss = 3.5427\n",
      "It took 67.27619671821594 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "def train_model(batch_size=32):\n",
    "    start = time.time()\n",
    "    for epoch in range(5):\n",
    "        x_batch = []\n",
    "        y_batch = []\n",
    "        for step, (x, y) in enumerate(zip(x_train, y_train)):\n",
    "            if step % batch_size == batch_size-1:\n",
    "                x_batch.append(x)\n",
    "                y_batch.append(y)\n",
    "                loss = train_step(np.array(x_batch), np.array(y_batch))\n",
    "                x_batch = []\n",
    "                y_batch = []\n",
    "        print('Epoch %d: last batch loss = %.4f' % (epoch, float(loss)))\n",
    "    print(\"It took {} seconds\".format(time.time() - start))\n",
    "\n",
    "train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0548"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "prediction = model.predict(x_test, batch_size=x_test.shape[0], verbose=1)\n",
    "temp = sum(np.squeeze(y_test) == np.argmax(prediction, axis=1))\n",
    "temp/len(y_test)  # Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
